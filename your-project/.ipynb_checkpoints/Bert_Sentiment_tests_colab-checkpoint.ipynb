{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-YbjCkzw0yU",
    "outputId": "09c2bb72-81da-4709-bd53-2e3e90740770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |                                | 10kB 31.3MB/s eta 0:00:01\r",
      "\u001b[K     |▏                               | 20kB 32.7MB/s eta 0:00:01\r",
      "\u001b[K     |▎                               | 30kB 20.6MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 40kB 24.3MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 51kB 25.3MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 61kB 28.0MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 71kB 18.8MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 81kB 20.2MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 92kB 18.6MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 102kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 112kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 122kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 133kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 143kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 153kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 163kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 174kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 184kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 194kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 204kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 215kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 225kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 235kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 245kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 256kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 266kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 276kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 286kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 296kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 307kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 317kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 327kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 337kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 348kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 358kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 368kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 378kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 389kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 399kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 409kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 419kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 430kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 440kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 450kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 460kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 471kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 481kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 491kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 501kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 512kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 522kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 532kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 542kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 552kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 563kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 573kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 583kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 593kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 604kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 614kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 624kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 634kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 645kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 655kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 665kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 675kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 686kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 696kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 706kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 716kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 727kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 737kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 747kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 757kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 768kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 778kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 788kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 798kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 808kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 819kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 829kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 839kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 849kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 860kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 870kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 880kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 890kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 901kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 911kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 921kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 931kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 942kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 952kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 962kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 972kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 983kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 993kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 1.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 1.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 1.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 1.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 1.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 1.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 1.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 1.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 1.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 1.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 1.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 1.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 1.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 1.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 2.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 2.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 2.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 2.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 2.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 2.5MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 2.6MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 2.7MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 2.8MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 2.9MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 3.0MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 3.1MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 3.2MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 3.3MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 3.4MB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 3.4MB 18.4MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "!pip install -q tensorflow-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w_XlxN1IsRJ"
   },
   "source": [
    "You will use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-P1ZOA0FkVJ",
    "outputId": "ce1865c3-3743-49d2-95ac-87e4ecefd4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.1MB 20.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 174kB 56.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 706kB 53.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 358kB 51.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 102kB 14.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 645kB 50.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 37.6MB 80kB/s \n",
      "\u001b[K     |████████████████████████████████| 1.2MB 49.3MB/s \n",
      "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_XgTpm9ZxoN9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optmizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "ziZYIKl_ZAwO",
    "outputId": "80115c24-314a-45f4-def2-b12e13f01b8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4845 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LABEL_COLUMN                                        DATA_COLUMN\n",
       "0              0.5  Technopolis plans to develop in stages an area...\n",
       "1              0.0  The international electronic industry company ...\n",
       "2              1.0  With the new production plant the company woul...\n",
       "3              1.0  According to the company 's updated strategy f...\n",
       "4              1.0  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...\n",
       "...            ...                                                ...\n",
       "4840           0.0  LONDON MarketWatch -- Share prices ended lower...\n",
       "4841           0.5  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4842           0.0  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4843           0.0  Net sales of the Paper segment decreased to EU...\n",
       "4844           0.0  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4845 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('/content/all-data.csv', encoding='latin-1')\n",
    "dataset.columns = ['LABEL_COLUMN', 'DATA_COLUMN']\n",
    "dataset\n",
    "\n",
    "labels = pd.get_dummies(dataset.LABEL_COLUMN)\n",
    "labels = np.array(labels)\n",
    "labels\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "transformed_d = le.fit_transform(dataset.LABEL_COLUMN)\n",
    "dataset.LABEL_COLUMN = transformed_d\n",
    "dataset.LABEL_COLUMN = dataset.LABEL_COLUMN/2\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vkvMf6Z_vZOF"
   },
   "outputs": [],
   "source": [
    "labels = np.array(dataset.LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pOdqCMoQDRJL"
   },
   "outputs": [],
   "source": [
    "data=tf.convert_to_tensor(dataset.DATA_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX8FtlpGJRE6"
   },
   "source": [
    "## Loading models from TensorFlow Hub\n",
    "\n",
    "Here you can choose which BERT model you will load from TensorFlow Hub and fine-tune. There are multiple BERT models available.\n",
    "\n",
    "  - [BERT-Base](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3), [Uncased](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3) and [seven more models](https://tfhub.dev/google/collections/bert/1) with trained weights released by the original BERT authors.\n",
    "  - [Small BERTs](https://tfhub.dev/google/collections/bert/1) have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.\n",
    "  - [ALBERT](https://tfhub.dev/google/collections/albert/1): four different sizes of \"A Lite BERT\" that reduces model size (but not computation time) by sharing parameters between layers.\n",
    "  - [BERT Experts](https://tfhub.dev/google/collections/experts/bert/1): eight models that all have the BERT-base architecture but offer a choice between different pre-training domains, to align more closely with the target task.\n",
    "  - [Electra](https://tfhub.dev/google/collections/electra/1) has the same architecture as BERT (in three different sizes), but gets pre-trained as a discriminator in a set-up that resembles a Generative Adversarial Network (GAN).\n",
    "  - BERT with Talking-Heads Attention and Gated GELU [[base](https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1), [large](https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_large/1)] has two improvements to the core of the Transformer architecture.\n",
    "\n",
    "The model documentation on TensorFlow Hub has more details and references to the\n",
    "research literature. Follow the links above, or click on the [`tfhub.dev`](http://tfhub.dev) URL\n",
    "printed after the next cell execution.\n",
    "\n",
    "The suggestion is to start with a Small BERT (with fewer parameters) since they are faster to fine-tune. If you like a small model but with higher accuracy, ALBERT might be your next option. If you want even better accuracy, choose\n",
    "one of the classic BERT sizes or their recent refinements like Electra, Talking Heads, or a BERT Expert.\n",
    "\n",
    "Aside from the models available below, there are [multiple versions](https://tfhub.dev/google/collections/transformer_encoders_text/1) of the models that are larger and can yeld even better accuracy but they are too big to be fine-tuned on a single GPU. You will be able to do that on the [Solve GLUE tasks using BERT on a TPU colab](https://www.tensorflow.org/tutorials/text/solve_glue_tasks_using_bert_on_tpu).\n",
    "\n",
    "You'll see in the code below that switching the tfhub.dev URL is enough to try any of these models, because all the differences between them are encapsulated in the SavedModels from TF Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:35:28.458154Z",
     "start_time": "2021-03-11T20:35:28.421179Z"
    },
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8_ctG55-uTX",
    "outputId": "45b016fa-3918-4875-bae8-7c1f46c89232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "#@title Choose a BERT model to fine-tune\n",
    "\n",
    "bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WrcxxTRDdHi"
   },
   "source": [
    "## The preprocessing model\n",
    "\n",
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models discussed above, which implements this transformation using TF ops from the TF.text library. It is not necessary to run pure Python code outside your TensorFlow model to preprocess text.\n",
    "\n",
    "The preprocessing model must be the one referenced by the documentation of the BERT model, which you can read at the URL printed above. For BERT models from the drop-down above, the preprocessing model is selected automatically.\n",
    "\n",
    "Note: You will load the preprocessing model into a [hub.KerasLayer](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) to compose your fine-tuned model. This is the preferred API to load a TF2-style SavedModel from TF Hub into a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0SQi-jWd_jzq"
   },
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKnLPSEmtp9i"
   },
   "source": [
    "## Using the BERT model\n",
    "\n",
    "Before putting BERT into your own model, let's take a look at its outputs. You will load it from TF Hub and see the returned values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tXxYpK8ixL34"
   },
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm61jDrezAll"
   },
   "source": [
    "The BERT models return a map with 3 important keys: `pooled_output`, `sequence_output`, `encoder_outputs`:\n",
    "\n",
    "- `pooled_output` to represent each input sequence as a whole. The shape is `[batch_size, H]`. You can think of this as an embedding for the entire movie review.\n",
    "- `sequence_output` represents each input token in the context. The shape is `[batch_size, seq_length, H]`. You can think of this as a contextual embedding for every token in the movie review.\n",
    "- `encoder_outputs` are the intermediate activations of the `L` Transformer blocks. `outputs[\"encoder_outputs\"][i]` is a Tensor of shape `[batch_size, seq_length, 1024]` with the outputs of the i-th Transformer block, for `0 <= i < L`. The last value of the list is equal to `sequence_output`.\n",
    "\n",
    "For the fine-tuning you are going to use the `pooled_output` array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDNKfAXbDnJH"
   },
   "source": [
    "## Define your model\n",
    "\n",
    "You will create a very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer.\n",
    "\n",
    "Note: for more information about the base model's input and output you can use just follow the model's url for documentation. Here specifically you don't need to worry about it because the preprocessing model will take care of that for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "aksj743St9ga"
   },
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string,name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1,activation='relu', name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "0EmzyHZXKIpm",
    "outputId": "0f7a1e3b-ac3d-4d18-d6f9-393805a5155d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbUWoZMwc302"
   },
   "source": [
    "## Model training\n",
    "\n",
    "You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpJ3xcwDT56v"
   },
   "source": [
    "### Loss function\n",
    "\n",
    "Since this is a binary classification problem and the model outputs a probability (a single-unit layer), you'll use `losses.BinaryCrossentropy` loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OWPOZE-L3AgE"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanSquaredError()#CategoricalCrossentropy(from_logits=True) \n",
    "metrics = ['accuracy']#tf.metrics.#CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77psrpfzbxtp"
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "For fine-tuning, let's use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://arxiv.org/abs/1711.05101).\n",
    "\n",
    "For the learning rate (`init_lr`), we use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (`num_warmup_steps`). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "P9eP2y9dbw32"
   },
   "outputs": [],
   "source": [
    "epochs = 9\n",
    "steps_per_epoch = len(data)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqlarlpC_v0g"
   },
   "source": [
    "### Loading the BERT model and training\n",
    "\n",
    "Using the `classifier_model` you created earlier, you can compile the model with the loss, metric and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-7GPDhR98jsD"
   },
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpBuV5j2cS_b"
   },
   "source": [
    "Note: training time will vary depending on the complexity of the BERT model you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtfDFAnN_Neu",
    "outputId": "28c5cfcf-9b5e-4e7a-d3dc-ddddc205e86f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
      "Epoch 1/5\n",
      " 27/122 [=====>........................] - ETA: 1:23 - loss: 0.3373 - accuracy: 0.6651"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=data, y=labels, validation_split = 0.2, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBthMlTSV8kn"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Its a financial dataset so it performs well with financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slqB-urBV9sP",
    "outputId": "2a3a1c69-0f4d-49e3-e03e-c3637cbd8bf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5735099]]\n"
     ]
    }
   ],
   "source": [
    "#loss, accuracy = \n",
    "print(classifier_model.predict(tf.constant([\"We are all going to die \"])))\n",
    "\n",
    "#print(f'Loss: {loss}')\n",
    "#print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert Sentiment tests colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
